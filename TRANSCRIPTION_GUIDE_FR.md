# Guide D√©taill√© : Syst√®me de Transcription Audio/Vid√©o

## üìã Table des Mati√®res
1. [Vue d'ensemble](#vue-densemble)
2. [Architecture du syst√®me](#architecture-du-syst√®me)
3. [Flux de traitement complet](#flux-de-traitement-complet)
4. [Technologies utilis√©es](#technologies-utilis√©es)
5. [Explication d√©taill√©e du code](#explication-d√©taill√©e-du-code)
6. [Comment int√©grer la transcription](#comment-int√©grer-la-transcription)
7. [Exemples d'utilisation](#exemples-dutilisation)

---

## üéØ Vue d'ensemble

Votre projet utilise un syst√®me de transcription automatique qui convertit les fichiers audio et vid√©o en texte, puis enrichit ce texte avec des m√©tadonn√©es intelligentes (tags, r√©sum√©, mood, etc.).

### Fonctionnalit√©s principales :
- ‚úÖ **Transcription audio/vid√©o** ‚Üí Texte
- ‚úÖ **G√©n√©ration automatique de tags** et titre
- ‚úÖ **Cr√©ation de r√©sum√©s** intelligents
- ‚úÖ **D√©tection de l'humeur** (mood)
- ‚úÖ **G√©n√©ration de listes TODO** bas√©es sur le contenu
- ‚úÖ **G√©n√©ration d'images** √† partir de la transcription

---

## üèóÔ∏è Architecture du syst√®me

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (React)                          ‚îÇ
‚îÇ  - AudioManager.js : Upload fichiers audio/vid√©o            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  BACKEND API (Express)                       ‚îÇ
‚îÇ  - Route: POST /api/audio/upload                            ‚îÇ
‚îÇ  - Middleware: Multer (gestion upload fichiers)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              AudioService.js (Service principal)             ‚îÇ
‚îÇ  1. Upload vers Cloudinary                                   ‚îÇ
‚îÇ  2. Transcription via AssemblyAI                            ‚îÇ
‚îÇ  3. Traitement IA via AutomaticService                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   AssemblyAI     ‚îÇ          ‚îÇ  AutomaticService    ‚îÇ
‚îÇ  (Transcription) ‚îÇ          ‚îÇ  (IA - LLaMA 3.3)    ‚îÇ
‚îÇ                  ‚îÇ          ‚îÇ  - Tags              ‚îÇ
‚îÇ  Audio ‚Üí Texte   ‚îÇ          ‚îÇ  - Titre             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ  - R√©sum√©            ‚îÇ
                              ‚îÇ  - Mood              ‚îÇ
                              ‚îÇ  - TODO List         ‚îÇ
                              ‚îÇ  - Images            ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Flux de traitement complet

### √âtape 1 : Upload du fichier
```javascript
// Frontend envoie le fichier
POST /api/audio/upload
Content-Type: multipart/form-data
Body: {
  audio: [fichier audio/vid√©o],
  description: "Description du fichier"
}
```

### √âtape 2 : Sauvegarde et upload Cloudinary
```javascript
// AudioService.createAudio()
1. Sauvegarde temporaire du fichier (uploads/audio/)
2. Calcul de la dur√©e avec FFmpeg
3. Upload vers Cloudinary (stockage cloud)
4. Cr√©ation de l'enregistrement dans MongoDB
5. Suppression du fichier temporaire
```

### √âtape 3 : Transcription (AssemblyAI)
```javascript
// AudioService.audioTranscript()
1. Envoi de l'URL Cloudinary √† AssemblyAI
2. AssemblyAI traite l'audio/vid√©o
3. Polling toutes les 3 secondes pour v√©rifier l'√©tat
4. R√©cup√©ration du texte transcrit
```

### √âtape 4 : Enrichissement IA (LLaMA)
```javascript
// AutomaticService.generateTagsTitle()
1. Envoi de la transcription √† LLaMA 3.3
2. G√©n√©ration de :
   - Titre descriptif
   - Tags pertinents
   - Mood (humeur)
   - R√©sum√©
```

### √âtape 5 : Sauvegarde finale
```javascript
// AudioService.processAudio()
1. Sauvegarde de la transcription (Transcription model)
2. Sauvegarde du r√©sum√© (Summary model)
3. Cr√©ation/r√©cup√©ration des tags (Tag model)
4. Mise √† jour de l'audio avec toutes les m√©tadonn√©es
5. Changement du statut : pending ‚Üí processing ‚Üí ready
```

---

## üõ†Ô∏è Technologies utilis√©es

### 1. **AssemblyAI** (Transcription)
- **R√¥le** : Convertit audio/vid√©o en texte
- **Mod√®le** : "best" (meilleure pr√©cision)
- **Langues** : Anglais (configurable pour fran√ßais)
- **Configuration** : `backend/config/assemblyAi.js`

```javascript
const { AssemblyAI } = require('assemblyai');
const client = new AssemblyAI({
  apiKey: process.env.ASSEMBLYAI_API_KEY
});
```

### 2. **LLaMA 3.3** via OpenRouter (IA)
- **R√¥le** : Analyse intelligente du texte
- **Mod√®le** : `meta-llama/llama-3.3-70b-instruct`
- **Fonctions** :
  - G√©n√©ration de tags
  - Cr√©ation de titres
  - R√©sum√©s
  - D√©tection d'humeur
  - Listes TODO

### 3. **Cloudinary** (Stockage)
- **R√¥le** : H√©bergement des fichiers audio/vid√©o
- **Avantages** : URLs permanentes, streaming optimis√©

### 4. **FFmpeg** (M√©tadonn√©es)
- **R√¥le** : Extraction de la dur√©e des fichiers
- **Fallback** : Estimation bas√©e sur la taille si FFmpeg absent

### 5. **Multer** (Upload)
- **R√¥le** : Gestion des uploads multipart/form-data
- **Limite** : 100MB par fichier
- **Formats accept√©s** : audio/* et video/*

---

## üìù Explication d√©taill√©e du code

### 1. Route d'upload (`backend/route/audio.js`)

```javascript
router.post('/upload', requireAuth, upload.single('audio'), async (req, res) => {
  // 1. V√©rification du fichier
  if (!req.file) {
    return res.status(400).json({ message: 'No audio file provided' });
  }

  // 2. Cr√©ation de l'audio (upload Cloudinary)
  const result = await AudioService.createAudio(req.file, description, userId);
  
  // 3. Transcription et traitement IA (ATTEND la fin)
  await AudioService.processAudio(audio);
  
  // 4. Retour de l'audio complet avec transcription
  res.json({ status: 'success', data: completeAudio });
});
```

**Points cl√©s** :
- `requireAuth` : V√©rifie que l'utilisateur est connect√©
- `upload.single('audio')` : Multer g√®re l'upload
- `await processAudio()` : **Bloquant** - attend la fin de la transcription

---

### 2. Service Audio (`backend/services/AudioService.js`)

#### a) Cr√©ation de l'audio
```javascript
async createAudio(audioFile, description, userId) {
  // 1. V√©rifier que le fichier existe
  if (!fs.existsSync(audioPath)) {
    throw new Error('File not found');
  }
  
  // 2. Obtenir la dur√©e
  const duration = await this.getAudioDuration(audioPath);
  
  // 3. Upload vers Cloudinary
  const uploadResult = await this.uploadAudio(audioPath);
  
  // 4. Cr√©er l'enregistrement MongoDB
  const audio = new Audio({
    user_id: userId,
    file_url: uploadResult.data,
    description,
    duration,
    status: 'pending'
  });
  
  await audio.save();
  return { status: 'success', data: audio };
}
```

#### b) Transcription
```javascript
async audioTranscript(audioPath) {
  // 1. Configuration des param√®tres
  const params = {
    audio: audioPath,           // URL Cloudinary
    language_code: 'en',        // Langue (en/fr)
    speech_model: "best",       // Mod√®le de qualit√©
    punctuate: true,            // Ponctuation automatique
    format_text: true           // Formatage du texte
  };
  
  // 2. Lancer la transcription
  const transcript = await client.transcripts.transcribe(params);
  
  // 3. Polling pour attendre la fin
  let completedTranscript;
  do {
    await new Promise(r => setTimeout(r, 3000)); // Attendre 3 secondes
    completedTranscript = await client.transcripts.get(transcript.id);
  } while (completedTranscript.status !== "completed");
  
  // 4. Retourner le texte
  return {
    status: 'success',
    text: completedTranscript.text
  };
}
```

**Pourquoi le polling ?**
- AssemblyAI traite de mani√®re asynchrone
- Le temps d√©pend de la longueur du fichier
- On v√©rifie toutes les 3 secondes si c'est termin√©

#### c) Traitement complet
```javascript
async processAudio(audio) {
  // 1. Mettre √† jour le statut
  await Audio.findByIdAndUpdate(audio._id, { status: 'processing' });
  
  // 2. Transcription
  const transcriptResult = await this.audioTranscript(audio.file_url);
  const transcriptText = transcriptResult.text;
  
  // 3. G√©n√©ration des m√©tadonn√©es IA
  const taggingResult = await this.autoTagging(transcriptText);
  const { title, tags, mood, summary } = taggingResult.data;
  
  // 4. Cr√©er/trouver les tags
  const tagInstances = await Promise.all(
    tags.map(async tagName => {
      let tag = await Tag.findOne({ name: tagName });
      if (!tag) {
        tag = new Tag({ name: tagName });
        await tag.save();
      }
      return tag._id;
    })
  );
  
  // 5. Sauvegarder la transcription
  const transcription = new Transcription({
    audio_id: audio._id,
    text: transcriptText
  });
  await transcription.save();
  
  // 6. Sauvegarder le r√©sum√©
  const summaryInstance = new Summary({
    audio_id: audio._id,
    summary_text: summary
  });
  await summaryInstance.save();
  
  // 7. Mettre √† jour l'audio
  await Audio.findByIdAndUpdate(audio._id, {
    title,
    mood,
    status: 'ready',
    tags: tagInstances,
    transcription: transcription._id,
    summary: summaryInstance._id
  });
}
```

---

### 3. Service Automatique (`backend/services/AutomaticService.js`)

#### a) G√©n√©ration de tags et m√©tadonn√©es
```javascript
async generateTagsTitle(transcription) {
  // 1. Cr√©er le prompt pour l'IA
  const prompt = `Analyze this audio transcription and respond ONLY with valid JSON:

Transcription: "${transcription}"

Respond with this exact JSON structure:
{
  "title": "A short descriptive title (max 50 chars)",
  "tags": ["tag1", "tag2", "tag3"],
  "mood": "positive/negative/neutral/excited/sad",
  "summary": "Brief summary (max 200 chars)"
}`;

  // 2. Appeler LLaMA
  let text = await this.callLlama(prompt);
  
  // 3. Nettoyer la r√©ponse (enlever markdown)
  text = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
  
  // 4. Parser le JSON
  const jsonMatch = text.match(/\{[\s\S]*\}/);
  const parsedResult = JSON.parse(jsonMatch[0]);
  
  // 5. Retourner les donn√©es
  return {
    status: 'success',
    data: parsedResult
  };
}
```

#### b) G√©n√©ration de TODO list
```javascript
async generateTodoList(transcription) {
  const prompt = `Based on this audio transcription, generate a practical to-do list:

Transcription: "${transcription}"

Respond ONLY with valid JSON:
{
  "todos": [
    {
      "task": "Clear, actionable task description",
      "priority": "high/medium/low",
      "category": "learning/action/research/practice"
    }
  ],
  "keyTakeaways": ["takeaway 1", "takeaway 2", "takeaway 3"]
}`;

  let text = await this.callLlama(prompt);
  // ... parsing similaire
}
```

#### c) G√©n√©ration d'images
```javascript
async generateImageFromTranscription(transcription) {
  // 1. G√©n√©rer un prompt d'image avec LLaMA
  const promptGenerationPrompt = `Based on this audio transcription, create a concise image prompt:
  
Transcription: "${transcription.substring(0, 500)}"

Respond with ONLY the image prompt text.`;

  const imagePrompt = await this.callLlama(promptGenerationPrompt);
  
  // 2. G√©n√©rer l'image avec Pollinations.ai (gratuit)
  const encodedPrompt = encodeURIComponent(imagePrompt.trim());
  const pollinationsUrl = `https://image.pollinations.ai/prompt/${encodedPrompt}?width=1024&height=1024&nologo=true`;
  
  const response = await axios.get(pollinationsUrl, {
    responseType: 'arraybuffer'
  });
  
  // 3. Convertir en base64
  const imageBuffer = Buffer.from(response.data);
  const base64Image = imageBuffer.toString('base64');
  
  return {
    status: 'success',
    data: {
      imagePrompt: imagePrompt.trim(),
      imageBase64: base64Image,
      imageUrl: `data:image/png;base64,${base64Image}`
    }
  };
}
```

---

## üîå Comment int√©grer la transcription

### Option 1 : Utiliser le syst√®me existant

Votre syst√®me est d√©j√† int√©gr√© ! Il suffit d'uploader un fichier :

```javascript
// Frontend (React)
const handleUpload = async (file, description) => {
  const formData = new FormData();
  formData.append('audio', file);
  formData.append('description', description);
  
  const response = await fetch('http://localhost:5000/api/audio/upload', {
    method: 'POST',
    body: formData,
    credentials: 'include' // Important pour les sessions
  });
  
  const result = await response.json();
  console.log('Transcription:', result.data.transcription.text);
  console.log('Tags:', result.data.tags);
  console.log('R√©sum√©:', result.data.summary.summary_text);
};
```

---

### Option 2 : Ajouter la transcription √† un nouveau composant

#### √âtape 1 : Cr√©er un nouveau composant React

```javascript
// src/components/VideoTranscriber.js
import React, { useState } from 'react';

function VideoTranscriber() {
  const [file, setFile] = useState(null);
  const [transcription, setTranscription] = useState('');
  const [loading, setLoading] = useState(false);

  const handleFileChange = (e) => {
    setFile(e.target.files[0]);
  };

  const handleSubmit = async (e) => {
    e.preventDefault();
    setLoading(true);

    const formData = new FormData();
    formData.append('audio', file);
    formData.append('description', 'Ma vid√©o');

    try {
      const response = await fetch('http://localhost:5000/api/audio/upload', {
        method: 'POST',
        body: formData,
        credentials: 'include'
      });

      const result = await response.json();
      
      if (result.status === 'success') {
        setTranscription(result.data.transcription.text);
        alert('Transcription termin√©e !');
      }
    } catch (error) {
      console.error('Erreur:', error);
      alert('Erreur lors de la transcription');
    } finally {
      setLoading(false);
    }
  };

  return (
    <div>
      <h2>Transcrire une vid√©o/audio</h2>
      
      <form onSubmit={handleSubmit}>
        <input 
          type="file" 
          accept="audio/*,video/*" 
          onChange={handleFileChange}
          required
        />
        <button type="submit" disabled={loading}>
          {loading ? 'Transcription en cours...' : 'Transcrire'}
        </button>
      </form>

      {transcription && (
        <div>
          <h3>Transcription :</h3>
          <p>{transcription}</p>
        </div>
      )}
    </div>
  );
}

export default VideoTranscriber;
```

#### √âtape 2 : Ajouter le composant √† votre App

```javascript
// src/App.js
import VideoTranscriber from './components/VideoTranscriber';

function App() {
  return (
    <div>
      <VideoTranscriber />
    </div>
  );
}
```

---

### Option 3 : Cr√©er une nouvelle route API personnalis√©e

```javascript
// backend/route/custom-transcription.js
const express = require('express');
const router = express.Router();
const AudioService = require('../services/AudioService');

// Route simplifi√©e pour transcription uniquement
router.post('/transcribe-only', upload.single('audio'), async (req, res) => {
  try {
    // 1. Upload vers Cloudinary
    const uploadResult = await AudioService.uploadAudio(req.file.path);
    
    // 2. Transcription uniquement
    const transcriptResult = await AudioService.audioTranscript(uploadResult.data);
    
    // 3. Retourner juste le texte
    res.json({
      status: 'success',
      transcription: transcriptResult.text
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

module.exports = router;
```

---

## üí° Exemples d'utilisation

### Exemple 1 : Transcription simple

```javascript
// Upload un fichier et obtenir la transcription
const file = document.getElementById('fileInput').files[0];
const formData = new FormData();
formData.append('audio', file);
formData.append('description', 'Mon cours de math√©matiques');

const response = await fetch('/api/audio/upload', {
  method: 'POST',
  body: formData,
  credentials: 'include'
});

const data = await response.json();
console.log('Transcription:', data.data.transcription.text);
```

### Exemple 2 : G√©n√©rer une TODO list

```javascript
// Apr√®s avoir upload√© un audio
const audioId = '507f1f77bcf86cd799439011';

const response = await fetch(`/api/audio/${audioId}/generate-todos`, {
  method: 'POST',
  credentials: 'include'
});

const result = await response.json();
console.log('TODOs:', result.data.todos);
console.log('Key Takeaways:', result.data.keyTakeaways);
```

### Exemple 3 : G√©n√©rer une image

```javascript
const response = await fetch(`/api/audio/${audioId}/generate-image`, {
  method: 'POST',
  credentials: 'include'
});

const result = await response.json();
const imageUrl = result.data.imageUrl; // data:image/png;base64,...
document.getElementById('myImage').src = imageUrl;
```

---

## üîß Configuration requise

### Variables d'environnement (.env)

```env
# AssemblyAI (Transcription)
ASSEMBLYAI_API_KEY=votre_cl√©_assemblyai

# Cloudinary (Stockage)
CLOUDINARY_CLOUD_NAME=votre_cloud_name
CLOUDINARY_API_KEY=votre_api_key
CLOUDINARY_API_SECRET=votre_api_secret

# MongoDB
MONGODB_URI=mongodb://localhost:27017/votre_db

# Session
SESSION_SECRET=votre_secret_session
```

### Installation des d√©pendances

```bash
# Backend
cd backend
npm install assemblyai @huggingface/inference axios cloudinary fluent-ffmpeg multer

# Frontend
cd ../
npm install
```

---

## üìä Mod√®les de donn√©es

### Audio
```javascript
{
  _id: ObjectId,
  user_id: ObjectId,
  file_url: String,        // URL Cloudinary
  description: String,
  duration: Number,        // en secondes
  title: String,           // G√©n√©r√© par IA
  mood: String,            // positive/negative/neutral
  status: String,          // pending/processing/ready/error
  tags: [ObjectId],        // R√©f√©rences aux tags
  transcription: ObjectId, // R√©f√©rence √† Transcription
  summary: ObjectId,       // R√©f√©rence √† Summary
  createdAt: Date
}
```

### Transcription
```javascript
{
  _id: ObjectId,
  audio_id: ObjectId,
  text: String,            // Texte complet de la transcription
  createdAt: Date
}
```

### Summary
```javascript
{
  _id: ObjectId,
  audio_id: ObjectId,
  summary_text: String,    // R√©sum√© g√©n√©r√© par IA
  createdAt: Date
}
```

### Tag
```javascript
{
  _id: ObjectId,
  name: String,            // Nom du tag
  createdAt: Date
}
```

---

## üöÄ Am√©liorations possibles

### 1. Support multilingue
```javascript
// Modifier dans AudioService.js
const params = {
  audio: audioPath,
  language_code: 'fr', // Changer en fran√ßais
  // ...
};
```

### 2. Transcription en temps r√©el
- Utiliser WebSocket pour le streaming
- Afficher la transcription au fur et √† mesure

### 3. Sous-titres pour vid√©os
- Utiliser les timestamps d'AssemblyAI
- G√©n√©rer des fichiers SRT/VTT

### 4. Recherche dans les transcriptions
```javascript
// Ajouter un index de recherche
router.get('/search', async (req, res) => {
  const { query } = req.query;
  const transcriptions = await Transcription.find({
    text: { $regex: query, $options: 'i' }
  });
  res.json(transcriptions);
});
```

---

## üêõ D√©pannage

### Probl√®me : "Transcription timeout"
**Solution** : Augmenter le nombre de polls
```javascript
pollCount < 200 // Au lieu de 100
```

### Probl√®me : "FFmpeg not found"
**Solution** : Le syst√®me utilise un fallback automatique bas√© sur la taille du fichier

### Probl√®me : "AssemblyAI API error"
**Solution** : V√©rifier que `ASSEMBLYAI_API_KEY` est d√©fini dans `.env`

### Probl√®me : "Cloudinary upload failed"
**Solution** : V√©rifier les credentials Cloudinary dans `.env`

---

## üìö Ressources

- [Documentation AssemblyAI](https://www.assemblyai.com/docs)
- [Documentation LLaMA](https://ai.meta.com/llama/)
- [Documentation Cloudinary](https://cloudinary.com/documentation)
- [Documentation Multer](https://github.com/expressjs/multer)

---

## ‚úÖ R√©sum√©

Votre syst√®me de transcription fonctionne en **5 √©tapes** :

1. **Upload** : Le fichier est upload√© via Multer
2. **Stockage** : Le fichier est sauvegard√© sur Cloudinary
3. **Transcription** : AssemblyAI convertit l'audio en texte
4. **Enrichissement** : LLaMA g√©n√®re tags, titre, r√©sum√©, mood
5. **Sauvegarde** : Tout est stock√© dans MongoDB

Le syst√®me est **enti√®rement automatique** et **bloquant** (attend la fin de la transcription avant de r√©pondre).

Pour l'int√©grer ailleurs, il suffit d'appeler l'API `/api/audio/upload` avec un fichier audio ou vid√©o !
